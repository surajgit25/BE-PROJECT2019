{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from matplotlib.pyplot import specgram\n",
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Input, Flatten, Dropout, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1437, 130)\n",
      "(1437,)\n",
      "(1437, 128)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data=pd.read_csv(\"mfcc_value.csv\")\n",
    "print(data.shape)\n",
    "y_data=data['code']\n",
    "print(y_data.shape)\n",
    "x_data=data.iloc[:,0:128]\n",
    "print(x_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 129)\n",
      "0     2\n",
      "1     4\n",
      "2     5\n",
      "3     6\n",
      "4     7\n",
      "5     8\n",
      "6    13\n",
      "7    14\n",
      "8    13\n",
      "Name: code, dtype: int64\n",
      "(9,)\n",
      "          mf1         mf2        mf3        mf4        mf5       mf6  \\\n",
      "0 -327.306962  105.179345  17.623314  -2.696320   5.376429 -3.240820   \n",
      "1 -403.739783  129.228934  14.467101 -11.688136   7.266967 -0.282509   \n",
      "2 -393.302717  126.521848  17.421019  -6.676395  10.861401  2.962282   \n",
      "3 -348.922161  116.166546  -1.478309  -7.617016   5.368340 -0.121965   \n",
      "4 -357.001502  118.919974  22.379507  -8.356089   9.486865 -1.869516   \n",
      "5 -324.592572   99.023570  15.558175 -11.434630   3.954232  1.914921   \n",
      "6 -375.231583  116.340491  14.958794  -2.394822  14.546546  2.994605   \n",
      "7 -299.942224  119.739845  -3.907728  -6.738251  12.360601 -4.643945   \n",
      "8 -693.069755   55.734569  -1.919739  16.408997   8.449357  0.220737   \n",
      "\n",
      "         mf7       mf8        mf9       mf10  ...     mf119     mf120  \\\n",
      "0  -1.531882 -2.161742  -3.977710  -6.634812  ...  0.033935 -0.056459   \n",
      "1   0.390265  0.753391 -12.604427   1.129080  ... -0.073606  0.100643   \n",
      "2   0.055202 -1.604983  -6.195038  -6.749198  ...  0.202332 -0.391480   \n",
      "3   7.081256 -5.048680 -13.816784  -1.249752  ... -0.058778 -0.302625   \n",
      "4   3.590476  4.322831 -11.116185  -7.635284  ...  0.164791 -0.243091   \n",
      "5 -10.569194 -3.870473  -8.753408  -6.319617  ... -0.108630 -0.555112   \n",
      "6  -5.541491 -0.065603 -11.115641  -9.467187  ...  0.260030 -0.353984   \n",
      "7 -12.576379  5.278786 -16.855145 -11.597785  ... -0.172231 -0.397532   \n",
      "8  -1.738341 -4.931290 -11.981821  -0.993779  ... -0.194311 -0.154405   \n",
      "\n",
      "      mf121     mf122     mf123     mf124     mf125     mf126     mf127  \\\n",
      "0  0.081145  0.226442  0.004318  0.491284  0.441646 -0.404232 -0.187221   \n",
      "1 -0.265649 -0.156753 -0.288160  0.543473 -0.288659 -0.431574 -0.188146   \n",
      "2 -0.015144  0.399972  0.038637  0.280539  0.250035  0.423193 -0.120402   \n",
      "3 -0.046139  0.321111  0.277819 -0.169793  0.073017  0.115024  0.177626   \n",
      "4 -0.147753  0.051035  0.125544  0.162355  0.051554  0.223166 -0.199048   \n",
      "5 -0.137276  0.152511  0.261512  0.038473  0.112876  0.115796 -0.003187   \n",
      "6 -0.055991  0.410163  0.437439  0.135660 -0.387117 -0.435068 -0.247713   \n",
      "7 -0.390619  0.145758 -0.100326  0.190395  0.437483 -0.153358 -0.015987   \n",
      "8 -0.034209 -0.206119 -0.089714 -0.224768 -0.008534 -0.064925 -0.158476   \n",
      "\n",
      "      mf128  \n",
      "0  0.061442  \n",
      "1 -0.140928  \n",
      "2 -0.115045  \n",
      "3 -0.350190  \n",
      "4  0.006921  \n",
      "5 -0.185941  \n",
      "6  0.034453  \n",
      "7 -0.034414  \n",
      "8  0.402392  \n",
      "\n",
      "[9 rows x 128 columns]\n",
      "(9, 128)\n"
     ]
    }
   ],
   "source": [
    "data1=pd.read_csv(\"Real_time.csv\")\n",
    "print(data1.shape)\n",
    "y_data1=data1['code']\n",
    "print(y_data1)\n",
    "print(y_data1.shape)\n",
    "x_data1=data1.drop('code',axis=1)\n",
    "print(x_data1)\n",
    "print(x_data1.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1437, 128)\n",
      "(9, 128)\n",
      "(1437,)\n",
      "(9,)\n",
      "1437\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "from  sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x_data,y_data,test_size=0.20,random_state=42)\n",
    "print(type(x_train))\n",
    "'''\n",
    "x_train=np.array(x_data)\n",
    "x_test=np.array(x_data1)\n",
    "#x_test=np.array([-347.3619807,117.6714815,9.636698304,-2.399916417,6.718877827,-2.199571386,0.167613441,0.461751707,-9.836163627,-13.80700098,-5.977382068,-0.356964871,-22.24708633,-11.38453699,-13.18409329,-16.03756441,-13.5893078,-6.493240063,-13.51482568,-9.581517251,-15.05839644,-7.721821973,-11.75244699,-5.313440719,-8.93558046,-5.079195191,-4.927472782,-2.955543768,-8.094937366,-1.544772881,-5.744328873,0.060461495,0.079197597,3.355840888,-2.025601815,0.208792797,-3.881217285,-4.418160144\t,4.932549512,-2.028811405,-3.683001971,-2.935637711,-3.429617157,-2.472812922,-1.904401643,-0.250673578,-1.338308434,-1.638154836,-2.957424407,-0.198096961,-1.052004405,0.775943144,-1.000892361,0.420038488,-1.932616921,-0.545699397,-2.2756138,-0.486405228,-0.547881455,0.576000244,-0.055779038,0.418568113,-0.285700142,0.481665428,-0.20811285,0.329298462,-0.384202921,0.798174655,0.603616923,0.712044429,-0.281327167,-0.028297694,-1.014965232,-0.218247954,-0.644526732,0.802521052,-0.172496525,0.240522864,-0.072180128,1.608995608,0.914925554,0.024946445,-0.375088451,-0.113388601,-0.511945557,-0.024807161,-0.0152855,-0.489971538,-0.67364052,0.141670697,0.637514927,0.200169103,-0.720486424,-0.58158334,-0.799433453,-0.027117851,-0.069269837,-0.612199379,-0.963938744,-0.815241227,0.075047759,0.531325533,0.313320477,0.05680688,-0.066852775,0.504121745,0.240642335,0.177325341,0.19924513,0.660659839,0.219763403,-0.379913085,0.004386723,0.306399983,0.330075546,0.106786125,0.505904784,-0.10836226,0.138086326,0.45813461,-0.067856264,0.078304252,-0.196212525,0.201982114,0.447975764,0.047926532,-0.274382859,-0.09031444\n",
    "#])[np.newaxis]\n",
    "np.transpose(x_test) \n",
    "y_train=np.array(y_data)\n",
    "y_test=np.array(y_data1)\n",
    "\n",
    "\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(len(x_train))\n",
    "\n",
    "\n",
    "print(type(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n"
     ]
    }
   ],
   "source": [
    "#(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "\n",
    "no_rows=len(x_train)\n",
    "training_epochs = 500\n",
    "learning_rate = 0.001\n",
    "batch_size = 40\n",
    "display_step = 10\n",
    "n_classes=16\n",
    "n_input= x_train.shape[1]\n",
    "print(n_input)\n",
    "n_hidden_1= 128\n",
    "n_hidden_2= 128\n",
    "n_hidden_3= 128\n",
    "n_hidden_4=128\n",
    "n_hidden_5=128\n",
    "n_hidden_6=128\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tf.one_hot(y_train, n_classes)\n",
    "y_test = tf.one_hot(y_test, n_classes)\n",
    "\n",
    "#Build the model\n",
    "\n",
    "x = tf.placeholder(\"float\", [None, n_input])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First Layer\n",
    "\n",
    "h1 = tf.Variable(tf.random_normal([n_input, n_hidden_1]))\n",
    "b1 = tf.Variable(tf.random_normal([n_hidden_1]))\n",
    "layer_1 = tf.nn.selu(x @ h1 + b1)\n",
    "\n",
    "## second layer\n",
    "h2 = tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2]))\n",
    "b2 = tf.Variable(tf.random_normal([n_hidden_2]))\n",
    "layer_2 = tf.nn.selu(layer_1 @ h2 + b2)\n",
    "\n",
    "## third layer\n",
    "h3 = tf.Variable(tf.random_normal([n_hidden_2, n_hidden_3]))\n",
    "b3 = tf.Variable(tf.random_normal([n_hidden_3]))\n",
    "layer_3 =tf.nn.selu(layer_2 @ h3 + b3)\n",
    "\n",
    "## fourth layer\n",
    "h4 = tf.Variable(tf.random_normal([n_hidden_3, n_hidden_4]))\n",
    "b4 = tf.Variable(tf.random_normal([n_hidden_4]))\n",
    "layer_4 =tf.nn.selu(layer_2 @ h4 + b4)\n",
    "\n",
    "## fifth layer\n",
    "h5 = tf.Variable(tf.random_normal([n_hidden_4, n_hidden_5]))\n",
    "b5 = tf.Variable(tf.random_normal([n_hidden_5]))\n",
    "layer_5 = tf.nn.selu(layer_2 @ h5 + b5)\n",
    "## sixth layer\n",
    "h6=tf.Variable(tf.random_normal([n_hidden_5,n_hidden_6]))\n",
    "b6=tf.Variable(tf.random_normal([n_hidden_6]))\n",
    "layer_6=tf.nn.selu(layer_2 @h6 + b6)\n",
    "\n",
    "\n",
    "\n",
    "##Final Output layer\n",
    "\n",
    "\n",
    "w = tf.Variable(tf.random_normal([n_hidden_6, n_classes]))\n",
    "b_out= tf.Variable(tf.random_normal([n_classes]))\n",
    "out_layer = layer_6 @ w + b_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"random_uniform_6:0\", shape=(40,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "##cost\n",
    "cost = tf.reduce_mean(tf.nn.\\\n",
    "                      softmax_cross_entropy_with_logits_v2(\\\n",
    "        logits=out_layer, labels=y))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=\\\n",
    "                                   learning_rate).minimize(cost)\n",
    "seed = 30\n",
    "tf.set_random_seed(seed)\n",
    "a = tf.random_uniform([batch_size],\\\n",
    "                      minval=0,maxval=len(x_train),\\\n",
    "                      dtype=tf.int64)\n",
    "print(a)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "total_batch = int(len(x_train)/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost= 356424.325000000\n",
      "Epoch: 0011 cost= 9634.036662946\n",
      "Epoch: 0021 cost= 5997.154701451\n",
      "Epoch: 0031 cost= 4459.248535156\n",
      "Epoch: 0041 cost= 3351.994353376\n",
      "Epoch: 0051 cost= 2910.309943499\n",
      "Epoch: 0061 cost= 2626.338078962\n",
      "Epoch: 0071 cost= 2409.663793945\n",
      "Epoch: 0081 cost= 2308.629331752\n",
      "Epoch: 0091 cost= 1814.887880162\n",
      "Epoch: 0101 cost= 1455.674309431\n",
      "Epoch: 0111 cost= 2228.455208915\n",
      "Epoch: 0121 cost= 1476.449272810\n",
      "Epoch: 0131 cost= 1405.567347063\n",
      "Epoch: 0141 cost= 1130.633122907\n",
      "Epoch: 0151 cost= 1032.255326625\n",
      "Epoch: 0161 cost= 1140.576133510\n",
      "Epoch: 0171 cost= 1087.663539342\n",
      "Epoch: 0181 cost= 817.370155988\n",
      "Epoch: 0191 cost= 870.968428258\n",
      "Epoch: 0201 cost= 791.317779977\n",
      "Epoch: 0211 cost= 668.799189976\n",
      "Epoch: 0221 cost= 1073.347059413\n",
      "Epoch: 0231 cost= 478.679512460\n",
      "Epoch: 0241 cost= 561.002508545\n",
      "Epoch: 0251 cost= 584.085304260\n",
      "Epoch: 0261 cost= 632.857803781\n",
      "Epoch: 0271 cost= 792.042758615\n",
      "Epoch: 0281 cost= 620.681968907\n",
      "Epoch: 0291 cost= 362.304785265\n",
      "Epoch: 0301 cost= 749.888728551\n",
      "Epoch: 0311 cost= 587.150467682\n",
      "Epoch: 0321 cost= 454.382172503\n",
      "Epoch: 0331 cost= 543.600724139\n",
      "Epoch: 0341 cost= 622.894587490\n",
      "Epoch: 0351 cost= 662.771239144\n",
      "Epoch: 0361 cost= 498.666445051\n",
      "Epoch: 0371 cost= 234.409570926\n",
      "Epoch: 0381 cost= 453.112176650\n",
      "Epoch: 0391 cost= 528.823108564\n",
      "Epoch: 0401 cost= 391.185006223\n",
      "Epoch: 0411 cost= 395.289679200\n",
      "Epoch: 0421 cost= 376.313518797\n",
      "Epoch: 0431 cost= 358.661435768\n",
      "Epoch: 0441 cost= 285.185225133\n",
      "Epoch: 0451 cost= 263.456848090\n",
      "Epoch: 0461 cost= 198.732312339\n",
      "Epoch: 0471 cost= 586.994600923\n",
      "Epoch: 0481 cost= 176.886651843\n",
      "Epoch: 0491 cost= 242.798691055\n",
      "Training phase finished\n",
      "Model accuracy: 0.22222222\n",
      "Tensor(\"Mean_13:0\", shape=(), dtype=float32)\n",
      "is: Tensor(\"ArgMax_20:0\", shape=(?,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    y_train=y_train.eval()\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.0\n",
    "        total_batch = int(len(x_train)/batch_size)\n",
    "        for i in range(batch_size):\n",
    "            #print('i', i)\n",
    "            a1=sess.run(a)\n",
    "            batch_xs = x_train[a1,:]\n",
    "            batch_ys = y_train[a1]\n",
    "                     \n",
    "            sess.run(optimizer, feed_dict={x: batch_xs, y: batch_ys})\n",
    "            avg_cost += sess.run(cost,feed_dict= {x: batch_xs,y: batch_ys})/total_batch\n",
    "            #print(avg_cost)\n",
    "        if epoch % display_step == 0: \n",
    "            print (\"Epoch:\", '%04d' % (epoch+1),\\\n",
    "                    \"cost=\", \"{:.9f}\".format(avg_cost))\n",
    "    print (\"Training phase finished\")\n",
    "    # Test model\n",
    "    correct_prediction = tf.equal (tf.argmax(out_layer, 1),tf.argmax(y, 1))\n",
    "   \n",
    "    # Calculate accuracy\n",
    "    y_test=y_test.eval()\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    print (\"Model accuracy:\", accuracy.eval({x: x_test,y:y_test}))\n",
    "    print(accuracy)\n",
    "    sf= tf.argmax(out_layer, 1)\n",
    "    print('is:', sf)\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
