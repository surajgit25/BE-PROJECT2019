{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from matplotlib.pyplot import specgram\n",
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Input, Flatten, Dropout, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1437, 130)\n",
      "(1437,)\n",
      "(1437, 128)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data=pd.read_csv(\"mfcc_value.csv\")\n",
    "print(data.shape)\n",
    "y_data=data['code']\n",
    "print(y_data.shape)\n",
    "x_data=data.iloc[:,0:128]\n",
    "print(x_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(288, 128)\n",
      "(1149,)\n",
      "(288,)\n",
      "1149\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "from  sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x_data,y_data,test_size=0.20,random_state=42)\n",
    "print(type(x_train))\n",
    "x_train=np.array(x_train)\n",
    "x_test=np.array(x_test)\n",
    "y_train=np.array(y_train)\n",
    "y_test=np.array(y_test)\n",
    "\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(len(x_train))\n",
    "\n",
    "\n",
    "print(type(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n"
     ]
    }
   ],
   "source": [
    "#(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "\n",
    "no_rows=len(x_train)\n",
    "training_epochs = 350\n",
    "learning_rate = 0.001\n",
    "batch_size = 40\n",
    "display_step = 10\n",
    "n_classes=16\n",
    "n_input= x_train.shape[1]\n",
    "print(n_input)\n",
    "n_hidden_1= 128\n",
    "n_hidden_2= 128\n",
    "n_hidden_3= 128\n",
    "n_hidden_4=128\n",
    "n_hidden_5=128\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tf.one_hot(y_train, n_classes)\n",
    "y_test = tf.one_hot(y_test, n_classes)\n",
    "\n",
    "#Build the model\n",
    "\n",
    "x = tf.placeholder(\"float\", [None, n_input])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First Layer\n",
    "\n",
    "h1 = tf.Variable(tf.random_normal([n_input, n_hidden_1]))\n",
    "b1 = tf.Variable(tf.random_normal([n_hidden_1]))\n",
    "layer_1 = tf.nn.selu(x @ h1 + b1)\n",
    "\n",
    "## second layer\n",
    "h2 = tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2]))\n",
    "b2 = tf.Variable(tf.random_normal([n_hidden_2]))\n",
    "layer_2 = tf.nn.selu(layer_1 @ h2 + b2)\n",
    "\n",
    "## third layer\n",
    "h3 = tf.Variable(tf.random_normal([n_hidden_2, n_hidden_3]))\n",
    "b3 = tf.Variable(tf.random_normal([n_hidden_3]))\n",
    "layer_3 =tf.nn.selu(layer_2 @ h3 + b3)\n",
    "\n",
    "## fourth layer\n",
    "h4 = tf.Variable(tf.random_normal([n_hidden_3, n_hidden_4]))\n",
    "b4 = tf.Variable(tf.random_normal([n_hidden_4]))\n",
    "layer_4 =tf.nn.selu(layer_2 @ h4 + b4)\n",
    "\n",
    "## fifth layer\n",
    "h5 = tf.Variable(tf.random_normal([n_hidden_4, n_hidden_5]))\n",
    "b5 = tf.Variable(tf.random_normal([n_hidden_5]))\n",
    "layer_5 = tf.nn.selu(layer_2 @ h5 + b5)\n",
    "\n",
    "\n",
    "##Final Output layer\n",
    "\n",
    "\n",
    "w = tf.Variable(tf.random_normal([n_hidden_5, n_classes]))\n",
    "b_out= tf.Variable(tf.random_normal([n_classes]))\n",
    "out_layer = layer_5 @ w + b_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"random_uniform_1:0\", shape=(40,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "##cost\n",
    "cost = tf.reduce_mean(tf.nn.\\\n",
    "                      softmax_cross_entropy_with_logits_v2(\\\n",
    "        logits=out_layer, labels=y))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=\\\n",
    "                                   learning_rate).minimize(cost)\n",
    "seed = 30\n",
    "tf.set_random_seed(seed)\n",
    "a = tf.random_uniform([batch_size],\\\n",
    "                      minval=0,maxval=len(x_train),\\\n",
    "                      dtype=tf.int64)\n",
    "print(a)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "total_batch = int(len(x_train)/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost= 244673.022042411\n",
      "Epoch: 0011 cost= 11994.410278320\n",
      "Epoch: 0021 cost= 7073.056335449\n",
      "Epoch: 0031 cost= 4930.208182199\n",
      "Epoch: 0041 cost= 3890.512939453\n",
      "Epoch: 0051 cost= 3031.843898228\n",
      "Epoch: 0061 cost= 2464.628104074\n",
      "Epoch: 0071 cost= 2241.383268084\n",
      "Epoch: 0081 cost= 1895.681276594\n",
      "Epoch: 0091 cost= 1935.439176287\n",
      "Epoch: 0101 cost= 1746.607045855\n",
      "Epoch: 0111 cost= 1630.820144653\n",
      "Epoch: 0121 cost= 1322.501944406\n",
      "Epoch: 0131 cost= 1142.740009308\n",
      "Epoch: 0141 cost= 843.727005005\n",
      "Epoch: 0151 cost= 1509.287802560\n",
      "Epoch: 0161 cost= 1235.167556218\n",
      "Epoch: 0171 cost= 1064.389302662\n",
      "Epoch: 0181 cost= 811.200398036\n",
      "Epoch: 0191 cost= 694.455720629\n",
      "Epoch: 0201 cost= 702.104039873\n",
      "Epoch: 0211 cost= 791.595409802\n",
      "Epoch: 0221 cost= 741.597745078\n",
      "Epoch: 0231 cost= 1093.330514635\n",
      "Epoch: 0241 cost= 518.533232689\n",
      "Epoch: 0251 cost= 652.946248736\n",
      "Epoch: 0261 cost= 858.820092882\n",
      "Epoch: 0271 cost= 476.968340465\n",
      "Epoch: 0281 cost= 1292.790656771\n",
      "Epoch: 0291 cost= 479.580578600\n",
      "Epoch: 0301 cost= 288.052500810\n",
      "Epoch: 0311 cost= 246.621157033\n",
      "Epoch: 0321 cost= 104.046125110\n",
      "Epoch: 0331 cost= 583.261626652\n",
      "Epoch: 0341 cost= 351.646900688\n",
      "Training phase finished\n",
      "Model accuracy: 0.5729167\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    y_train=y_train.eval()\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.0\n",
    "        total_batch = int(len(x_train)/batch_size)\n",
    "        for i in range(batch_size):\n",
    "            #print('i', i)\n",
    "            a1=sess.run(a)\n",
    "            batch_xs = x_train[a1,:]\n",
    "            batch_ys = y_train[a1]\n",
    "                     \n",
    "            sess.run(optimizer, feed_dict={x: batch_xs, y: batch_ys})\n",
    "            avg_cost += sess.run(cost,feed_dict= {x: batch_xs,y: batch_ys})/total_batch\n",
    "            #print(avg_cost)\n",
    "        if epoch % display_step == 0: \n",
    "            print (\"Epoch:\", '%04d' % (epoch+1),\\\n",
    "                    \"cost=\", \"{:.9f}\".format(avg_cost))\n",
    "    print (\"Training phase finished\")\n",
    "    # Test model\n",
    "    correct_prediction = tf.equal (tf.argmax(out_layer, 1),tf.argmax(y, 1))\n",
    "    # Calculate accuracy\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    print (\"Model accuracy:\", accuracy.eval({x: x_test,y:y_test.eval()}))\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
