{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1437, 130)\n",
      "(1437,)\n",
      "(1437, 128)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data=pd.read_csv(\"mfcc_value_128.csv\")\n",
    "print(data.shape)\n",
    "\n",
    "\n",
    "y_data=data['code']\n",
    "print(y_data.shape)\n",
    "x_data=data.iloc[:,0:128]\n",
    "print(x_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(288, 128)\n",
      "(1149,)\n",
      "(288,)\n",
      "1149\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "from  sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x_data,y_data,test_size=0.20,random_state=42)\n",
    "print(type(x_train))\n",
    "x_train=np.array(x_train)\n",
    "x_test=np.array(x_test)\n",
    "y_train=np.array(y_train)\n",
    "y_test=np.array(y_test)\n",
    "\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(len(x_train))\n",
    "\n",
    "\n",
    "print(type(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n"
     ]
    }
   ],
   "source": [
    "#(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "\n",
    "no_rows=len(x_train)\n",
    "training_epochs = 350\n",
    "learning_rate = 0.001\n",
    "batch_size = 40\n",
    "display_step = 10\n",
    "n_classes=16\n",
    "n_input= x_train.shape[1]\n",
    "print(n_input)\n",
    "n_hidden_1= 128\n",
    "n_hidden_2= 128\n",
    "n_hidden_3= 128\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tf.one_hot(y_train, n_classes)\n",
    "y_test = tf.one_hot(y_test, n_classes)\n",
    "\n",
    "#Build the model\n",
    "\n",
    "x = tf.placeholder(\"float\", [None, n_input])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First Layer\n",
    "\n",
    "h1 = tf.Variable(tf.random_normal([n_input, n_hidden_1]))\n",
    "b1 = tf.Variable(tf.random_normal([n_hidden_1]))\n",
    "layer_1 = tf.nn.leaky_relu(x @ h1 + b1)\n",
    "\n",
    "## second layer\n",
    "h2 = tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2]))\n",
    "b2 = tf.Variable(tf.random_normal([n_hidden_2]))\n",
    "layer_2 = tf.nn.leaky_relu(layer_1 @ h2 + b2)\n",
    "\n",
    "## third layer\n",
    "h3 = tf.Variable(tf.random_normal([n_hidden_2, n_hidden_3]))\n",
    "b3 = tf.Variable(tf.random_normal([n_hidden_3]))\n",
    "layer_3 = tf.nn.leaky_relu(layer_2 @ h3 + b3)\n",
    "\n",
    "\n",
    "\n",
    "##Final Output layer\n",
    "\n",
    "\n",
    "w = tf.Variable(tf.random_normal([n_hidden_3, n_classes]))\n",
    "b_out= tf.Variable(tf.random_normal([n_classes]))\n",
    "out_layer = layer_3 @ w + b_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"random_uniform_17:0\", shape=(40,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "##cost\n",
    "cost = tf.reduce_mean(tf.nn.\\\n",
    "                      softmax_cross_entropy_with_logits_v2(\\\n",
    "        logits=out_layer, labels=y))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=\\\n",
    "                                   learning_rate).minimize(cost)\n",
    "seed = 30\n",
    "tf.set_random_seed(seed)\n",
    "a = tf.random_uniform([batch_size],\\\n",
    "                      minval=0,maxval=len(x_train),\\\n",
    "                      dtype=tf.int64)\n",
    "print(a)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "total_batch = int(len(x_train)/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost= 200816.300362723\n",
      "Epoch: 0011 cost= 8799.352626256\n",
      "Epoch: 0021 cost= 5344.008701869\n",
      "Epoch: 0031 cost= 4286.780242920\n",
      "Epoch: 0041 cost= 3423.329489572\n",
      "Epoch: 0051 cost= 2883.152914865\n",
      "Epoch: 0061 cost= 2453.101486206\n",
      "Epoch: 0071 cost= 2633.747671945\n",
      "Epoch: 0081 cost= 2131.319856916\n",
      "Epoch: 0091 cost= 1834.938200814\n",
      "Epoch: 0101 cost= 1696.169677734\n",
      "Epoch: 0111 cost= 1798.621575492\n",
      "Epoch: 0121 cost= 1435.601487296\n",
      "Epoch: 0131 cost= 1619.120446341\n",
      "Epoch: 0141 cost= 1384.191712516\n",
      "Epoch: 0151 cost= 1080.824276515\n",
      "Epoch: 0161 cost= 1268.842426845\n",
      "Epoch: 0171 cost= 1247.836806161\n",
      "Epoch: 0181 cost= 787.828515734\n",
      "Epoch: 0191 cost= 607.454856328\n",
      "Epoch: 0201 cost= 1159.707657950\n",
      "Epoch: 0211 cost= 967.743721553\n",
      "Epoch: 0221 cost= 787.901763916\n",
      "Epoch: 0231 cost= 796.791452135\n",
      "Epoch: 0241 cost= 627.029317992\n",
      "Epoch: 0251 cost= 600.451322283\n",
      "Epoch: 0261 cost= 677.325477328\n",
      "Epoch: 0271 cost= 636.136758736\n",
      "Epoch: 0281 cost= 651.386835098\n",
      "Epoch: 0291 cost= 709.685776574\n",
      "Epoch: 0301 cost= 531.569658416\n",
      "Epoch: 0311 cost= 493.474217824\n",
      "Epoch: 0321 cost= 595.153363296\n",
      "Epoch: 0331 cost= 317.689759697\n",
      "Epoch: 0341 cost= 376.019827911\n",
      "Training phase finished\n",
      "Model accuracy: 0.5763889\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    y_train=y_train.eval()\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.0\n",
    "        total_batch = int(len(x_train)/batch_size)\n",
    "        for i in range(batch_size):\n",
    "            #print('i', i)\n",
    "            a1=sess.run(a)\n",
    "            batch_xs = x_train[a1,:]\n",
    "            batch_ys = y_train[a1]\n",
    "                     \n",
    "            sess.run(optimizer, feed_dict={x: batch_xs, y: batch_ys})\n",
    "            avg_cost += sess.run(cost,feed_dict= {x: batch_xs,y: batch_ys})/total_batch\n",
    "            #print(avg_cost)\n",
    "        if epoch % display_step == 0: \n",
    "            print (\"Epoch:\", '%04d' % (epoch+1),\\\n",
    "                    \"cost=\", \"{:.9f}\".format(avg_cost))\n",
    "    print (\"Training phase finished\")\n",
    "    # Test model\n",
    "    correct_prediction = tf.equal (tf.argmax(out_layer, 1),tf.argmax(y, 1))\n",
    "    # Calculate accuracy\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    print (\"Model accuracy:\", accuracy.eval({x: x_test,y:y_test.eval()}))\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
